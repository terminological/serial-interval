---
title: "Meta-analysis of the SARS-CoV-2 serial interval and the impact of parameter uncertainty on the COVID-19 reproduction number - Supplementary 1"
output:
  pdf_document :
    fig_caption: yes
knit: (function(inputFile, encoding,...) {
  options("spo.hidefigures"=FALSE);
  rmarkdown::render(
    inputFile,
    encoding = encoding,
    output_dir = here::here("output"), output_file=paste0('serial-intervals-suppl-1-',Sys.Date(),'.pdf'))
  })
header-includes:
 \usepackage{float}
 \floatplacement{figure}{H}
 `r huxtable::report_latex_dependencies()`
fig_width: 7
fig_height: 5
out.width: "100%"
bibliography: serial-interval.bib
csl: sage-vancouver.csl
vignette: >
  %\VignetteIndexEntry{COVID-19 Serial Intervals}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo = FALSE,
  warning = FALSE,
  message = FALSE,
  fig.align="center"
)
```

```{r setup}

library(tidyverse)
here::i_am("serial-intervals-suppl.Rmd")
source(here::here("serial-intervals-data.R"))
source(here::here("serial-intervals-captions.R"))
```

Robert Challen^1,2,3^; Ellen Brooks-Pollock^3,4^; Krasimira Tsaneva-Atanasova^1,5,6^; Leon Danon^4,5,6,7^

1) EPSRC Centre for Predictive Modelling in Healthcare, University of Exeter, Exeter, Devon, UK.
2) Somerset NHS Foundation Trust, Taunton, Somerset, UK.
3) Joint Universities Pandemic and Epidemiological Research (JUNIPER) consortium.
4) Bristol Medical School, Population Health Sciences, University of Bristol, Bristol, UK.
5) The Alan Turing Institute, British Library, 96 Euston Rd, London NW1 2DB, UK.
6) Data Science Institute, College of Engineering, Mathematics and Physical Sciences, University of Exeter, Exeter, UK. 
7) Department of Engineering Mathematics, University of Bristol, UK.

# Supporting tables and figures


## `r cap$stab("resampling-algo")`

The detail of the re-sampling algorithm that is used to combine estimates from a range of different studies is given below. The rationale for the definition of the sampling distributions is covered in more detail in Supplementary Materials 2. Teh algorithm combines raw data from original studies, with synthetic data from reasmpling the uncertain parameterised distributions provided in the literature. The combination of these is then used to compare different maximum likelihood parametric distributions fitting all the data, and later as a target for optimising the generation interval distribution when combined with a dataset of incubation period estimates.

_INPUTS:_

|   ***parameterised serial interval distributions***: 
|       list of parameterised serial interval distribution results from literature sources
|       comprising: 
|           ***source***, the study the estimates come from
|           ***distribution***, type of estimated serial interval distribution
|           ***central estimate of mean***, 
|           ***lower CI of mean***, if available
|           ***upper CI of mean***, if available
|           ***central estimate of sd***,
|           ***lower CI of sd***, if available
|           ***upper CI of sd***, if available
|           ***sample size***
|   ***raw serial interval observations***: 
|       raw data of empirical serial interval distributions from literature sources
|       comprising: 
|           ***source***,
|           set(***observed serial interval***)

_OUTPUT:_

|   ***output serial interval observations***: 
|       a set of 100 bootstrap replicates containing real and synthetic serial intervals observations
|       comprising: 
|           ***iteration***, 
|           set(***simulated serial interval***)

_ALGORITHM:_

|   for each ***source*** in ***raw serial interval observations***
|       define ***sample size*** as the count of ***observed serial interval***
|       for ***iteration*** in ***1 to 100***
|           define set(***samples***) as random re-samples with replacement from ***observed serial interval***
|           add (***iteration***, set(***samples***)) to ***output serial interval observations***
|   for each ***source*** in ***parameterised serial interval distributions***
|       --- we are recreating a set of sampling distributions $\mathcal{X}(\nu,\phi)$
|       --- where $\mathcal{X}$ as ***distribution*** from study ***source*** (e.g. gamma, log-normal, normal)
|       --- $\nu$ is a distribution of means compatible with study ***source***
|       --- and $\phi$ is a distribution of std devns compatible with study ***source***
|       --- $\nu$ is assumed to be a truncated normal distribution
|       --- and is the sample distribution of the mean
|       define $\mu_{mean}$ as ***central estimate of mean***
|       define $\sigma_{mean}$ as ***(upper CI of mean-lower CI of mean)/3.96*** or ***zero*** if CI not given
|       define $\nu \sim \mathcal{N}(\mu_{mean},\sigma_{mean})$ truncated between ***lower CI of mean*** and ***upper CI of mean***
|       --- $\phi$ is a Nakagami distributed quantity variously parameterised
|       --- depending on whether we have known confidence limits
|       --- this is the sample distribution of the standard deviation
|       define $\mu_{sd}$ as ***central estimate of sd***
|       define $N$ as ***sample size***
|       if ***lower CI of sd*** and ***upper CI of sd*** are defined
|           --- if we know confidence limits and mean of SD we assume it is Nakagami distributed
|           --- with $\Omega$ parameter as $\sigma^2$
|           fit $\phi \sim \text{Nakagami}(m_{sd},\sigma^2)$ to ***lower CI of sd*** and ***upper CI of sd***
|       else
|           --- if we know only know mean of SD (and sample size) we assume $\phi$ has a different parameterisation
|           define $\phi \sim \text{Nakagami}(\frac{N-1}{2},\sigma^2)$
|       for ***iteration*** in ***1 to 100***
|           define $\mu_{sample}$ as random sample from $\nu$
|           define $\sigma_{sample}$ as random sample from $\phi$
|           define ***sampling distribution*** $\sim \mathcal{X}(\mu_{sample},\sigma_{sample})$; converting parameters as necessary
|           define set(***samples***) as $N$ random samples from ***sampling distribution***
|           add (***iteration***, set(***samples***)) to ***output serial interval observations***
|   return ***output serial interval observations***

\newpage
## `r cap$stab("chess-trusts")`

The CHESS dataset includes a wide range of contributing hospitals with very varied data quality of submission. Only some hospitals continue to update their data, to include updates to patients as they are discharged or die, and only some submit data on all inpatients not just those who go to ITU. While investigating the delays to various events in the hospital stay we focussed on a subset of contributing hospitals that last updated records within 21 days of the date of analysis, and for which had a maximum of 20% of their cases had unknown or incomplete dates. This included the following contributing trusts and within these we excluded patients that had their COVID-19 diagnosis made more than 10 days after admission.

```{r}
CHESSClean %>% group_by(Trust = trustname) %>% summarise(Patients = n()) %>% standardPrintOutput::saveTable(here::here("output/TableS4_ChessTrusts"),defaultFontSize = 7)
```

\newpage
## `r cap$sfig("meta-analysis")`

Assessing the serial interval distribution using a random effects meta-analysis of the studies that report a confidence limit for the mean has the benefit of using a standardised methodology but does not describe the distributional nature of the serial interval.

```{r}
library(metaplus)
tmp = serialIntervals %>% mutate(yi = mean_si_estimate, sei = (mean_si_estimate_high_ci-mean_si_estimate_low_ci)/3.92) %>% filter(!is.na(sei)) %>% filter(assumed_distribution %in% c("gamma","lnorm","norm") & estimate_type %>% stringr::str_starts("serial"))
meanfit = suppressWarnings(metaplus::metaplus(tmp$yi, tmp$sei, slab=tmp$label, random="mixture"))
      
# plot(meanfit, cex=0.6, main="mean")

# tmp2 = serialIntervals %>% mutate(yi = std_si_estimate, sei = (std_si_estimate_high_ci-std_si_estimate_low_ci)/3.92) %>% filter(!is.na(sei)) %>% filter(assumed_distribution %in% c("gamma","lnorm","norm") & estimate_type %>% stringr::str_starts("serial"))
# sdfit = suppressWarnings(metaplus::metaplus(tmp2$yi, tmp2$sei, slab=tmp2$label, random="mixture"))
  

# p = patchwork::wrap_elements(full = ~ plot(meanfit, cex=0.4, main="mean"))+
#   patchwork::wrap_elements(full = ~ plot(sdfit, cex=0.4, main="std dev"))+
#   patchwork::plot_layout(ncol=2)
# 
# p %>% standardPrintOutput::saveThirdPageFigure(here::here("output/FigureS1_ParametersResampledSerialInterval")) 

# par(mfcol = c(1,2))
plot(meanfit, cex=0.8, main="")
# plot(sdfit, cex=0.4, main="std dev")
```

\newpage
## `r cap$stab("dfit-serial-interval-resample")`

Maximum likelihood parameterised distributions fitted to the resampled serial interval data demonstrate variable quality of fits, as the serial interval data has a substantial component which is negative and therefore fitting continuous distributions with support in the positive real numbers requires truncating the data at zero as seen in `r ref$fig("si-estimates")` in the main paper.

```{r}
siResampleDfit$printDistributionDetail() %>% ungroup() %>% mutate(AIC = sprintf("%1.1f",aic)) %>% select(N=n, AIC, Distribution, `Parameter / Moment` = param, `Mean ± SD (95% CI)`) %>% group_by(Distribution, AIC, N) %>% arrange(AIC) %>% standardPrintOutput::saveTable(here::here("output/TableS2_ParametersResampledSerialInterval"),defaultFontSize = 7)
```

\newpage
## `r cap$stab("dfit-serial-interval-ff100")`

The direct estimation of the serial interval from the FF100 data does not produce an estimatate that is comparable with other international data sets.

```{r}
siFF100$dfit$printDistributionDetail() %>% ungroup() %>% select(N=n, AIC=aic, Distribution, `Parameter / Moment` = param, `Mean ± SD (95% CI)`) %>% group_by(Distribution, AIC, N) %>% arrange(AIC) %>% standardPrintOutput::saveTable(here::here("output/TableS1_ParametersFF100SerialInterval"),defaultFontSize = 7)
```





\newpage
## `r cap$stab("incub-period-detail")`

Detail of the distribution parameterisation of the incubation period with the 3 investigated distributions on the 2 data sets, shows that in the larger Open COVID-19 Data working group data set the best fit is obtained with a log-normal distribution.

```{r}
bind_rows(
  incubFF100Fit$printDistributionDetail() %>% mutate(source = "FF100"),
  bopFit$printDistributionDetail() %>% mutate(source = "Open COVID-19 Data Working Group")
) %>% ungroup()  %>% mutate(AIC = sprintf("%1.1f",aic)) %>% select(Source = source, N = n, AIC, Distribution, `Parameter / Moment` = param, `Mean ± SD (95% CI)`) %>% arrange(N, AIC, Distribution) %>%
  group_by(N, Source, AIC, Distribution) %>% standardPrintOutput::saveTable(here::here("output/TableS3_IncubationPeriodsBeOutbreakPreparedAndFF100_Detail"),defaultFontSize = 7)
```

\newpage
## `r cap$sfig("gof-incub-fit")`

Further investigation of the fit of the log-normal incubation period demonstrates good alignment of the model fits in all models to the early part of the distribution but with some loss of fit towards the tails, due to a number of censored entries starting after day 28. These data are generally irrelevant given the incubation period distribution is largely only subsequently used in a discretised form up to a limited number of days. This poorly fitting tail could influence the upper confidence limit of the incubation period which may be slightly longer than anticipated.

```{r}
p1 = fitdistrplus::cdfcompcens(bopFit$distFits,plotstyle = "ggplot")+standardPrintOutput::smallLegend()+guides(linetype="none")+standardPrintOutput::defaultFigureLayout()+standardPrintOutput::narrower()
p2 = fitdistrplus::ppcompcens(bopFit$distFits,plotstyle = "ggplot")+standardPrintOutput::narrowAndTall()+standardPrintOutput::defaultFigureLayout()
p3 = fitdistrplus::qqcompcens(bopFit$distFits,plotstyle = "ggplot")+standardPrintOutput::narrowAndTall()+standardPrintOutput::defaultFigureLayout()
((p1|(p2/p3))+patchwork::plot_layout(ncol=2,widths=c(4,6))) %>% standardPrintOutput::saveHalfPageFigure(here::here("output/FigS1_GOFBeOutPrepSerialInterval"))
```

\newpage
## `r cap$sfig("parameter-distributions")`

The range of generation distributions resulting from optimising the different combinations of bootstrapped serial interval and incubation periods shows a spread of possible generation interval distributions, but mean and standard deviations are not wholly independent as seen in panel A, with a tendency to increasing SD with increasing mean. The shape and scale parameterisation shows a close reciprocal relationship between them due in some part to the constraints placed on the mean of the distributions.

The finding there the generation time mean and standard deviation distributions are not independent raises a question about whether sampling from uncertainly specified distributions can ever produce a realistic sample of generation time distributions for subsequent use in analysis. For example in estimating *R~t~* using the EpiEstim package uncertain parameterised distributions are sampled using independent truncated normal distributions on the mean and standard deviation and their associated confidence intervals. This will tend to broaden the range of considered distributions beyond that seen here, and hence increase uncertainty. It is possible that re-sampling using independent truncated normal distributed means and standard deviation could also bias estimates of *R~t~* but it is not obvious in which direction or by how much. This is an area for future investigation.

```{r}
# export distribution parameters
parameterDistributions = siGeneration$dfit$bootstraps %>% pivot_wider(names_from = "param",values_from = "value") %>% 
  mutate(mean = shape/rate, sd = sqrt(shape/(rate^2)))


p1 = ggplot(parameterDistributions,aes(x=mean,y=sd,colour=shape*rate))+geom_point(show.legend = FALSE)+scale_color_distiller(palette = "YlGnBu",trans="sqrt")
#p1a = ggExtra::ggMarginal(p1,type="density",fill="grey90")

p2 = ggplot(parameterDistributions,aes(x=shape,y=1/rate,colour=shape*rate))+geom_point(show.legend = FALSE)+scale_color_distiller(palette="YlGnBu",trans="sqrt")+ylab("scale")+coord_cartesian(xlim=c(0,25))
#p2a = ggExtra::ggMarginal(p2,type="density",fill="grey90")

p3 = patchwork::wrap_elements(p1)+patchwork::wrap_elements(p2)+patchwork::plot_layout(ncol=2)+patchwork::plot_annotation(tag_levels = "A")
p3 %>% saveHalfPageFigure(here::here("output/FigS3_GenerationIntervalParameterDistributions"))

```



\newpage
## `r cap$stab("chess-delay-params")`

The combination of incubation period and delay from symptom onset to positive test, admission or death are graphically displayed in `r ref$fig("chess-delay")`. Here the details of these parameterisations are provided. In all cases the best fit is obtained with a log-normal distribution. The infection to test distribution is used in the de-convolution analysis presented in the main paper.

```{r}
suppTable = bind_rows(
  #onsetFit$printDistributionDetail(),
  infectionToObservationFit$printDistributionDetail() 
) %>% ungroup()  %>% mutate(AIC = sprintf("%1.1f",aic)) %>% select(-dist,-bic,-aic,-loglik,-mean,-sd,-lower,-upper,-shift, -n) %>% rename(Transition = transition, Parameter= param)  %>% group_by(Transition, AIC, Distribution) %>% arrange(AIC)
suppTable %>% standardPrintOutput::saveTable(here::here("output/TableS4_ChessTimeDelayDistributionsDetail"),defaultFontSize = 7)
```

